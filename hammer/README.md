End-to-end Application
======================

ETL-recommendation Pipeline
----------------------------

Hammer is an end-to-end application to simulate the offline ETL-recommendation pipeline workload which daily occurs in a retailer Data Warehouse. Basically it consists of four steps:

1.    ETL: update the Data Warehouse with daily collected structural sales records and textual Apache logs

2.    Pref: calculate the user-item preferences regarding both sales history and Apache logs

3.    Sim: use the item-based collaborative filtering algorithm in mahout-0.7 to calculate the item-item similarity matrix which can be used for real-time recommendation

4.    Test: offline validate the item-item similarity matrix

The core data (i.e., sales table and related dimensional tables) are generated by TPC-DS (www.tpc.org/tpcds) data generating tool. The extended Apache logs are created by our random generator based on the core data.

To run the benchmark, You need to:

1.    Download the TPC-DS tool package and extract into a local directory

2.    Set the value of DBGEN_HOME in hammer/conf/configure.sh to be the full path to TPC-DS dir

3.    Set the value of STREAMING in hammer/conf/configure.sh to be the full path to hadoop-streaming-xxx.jar

4.    cd HIBENCH_ROOT_DIRECTORY

5.    bash hammer/bin/prepare.sh

6.    bash hammer/bin/run.sh
